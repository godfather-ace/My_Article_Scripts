{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Dependencies"
      ],
      "metadata": {
        "id": "3NRqAYE51gLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai unstructured==0.7.12 pinecone-client openai tiktoken langchain clean-text langchain-pinecone"
      ],
      "metadata": {
        "id": "V5S6OD9U-gRT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1774c5b-f14f-4d1d-b873-715f23bd6546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Collecting unstructured==0.7.12\n",
            "  Downloading unstructured-0.7.12-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pinecone-client\n",
            "  Downloading pinecone_client-4.1.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.5/215.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting clean-text\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting langchain-pinecone\n",
            "  Downloading langchain_pinecone-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Collecting argilla (from unstructured==0.7.12)\n",
            "  Downloading argilla-1.28.0-py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.2/421.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.12) (5.2.0)\n",
            "Collecting filetype (from unstructured==0.7.12)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.12) (4.9.4)\n",
            "Collecting msg-parser (from unstructured==0.7.12)\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.12) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.12) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.12) (2.0.3)\n",
            "Collecting pdf2image (from unstructured==0.7.12)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Collecting pdfminer.six (from unstructured==0.7.12)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.12) (9.4.0)\n",
            "Collecting pypandoc (from unstructured==0.7.12)\n",
            "  Downloading pypandoc-1.13-py3-none-any.whl (21 kB)\n",
            "Collecting python-docx (from unstructured==0.7.12)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-pptx (from unstructured==0.7.12)\n",
            "  Downloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from unstructured==0.7.12)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.12) (3.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.12) (2.31.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.12) (0.9.0)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.12) (2.0.1)\n",
            "Collecting langchain-core<0.3,>=0.1.46 (from langchain-openai)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.59-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Collecting emoji<2.0.0,>=1.0.0 (from clean-text)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text)\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pinecone-client\n",
            "  Downloading pinecone_client-3.2.2-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.9/215.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.13)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3,>=0.1.46->langchain-openai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3,>=0.1.46->langchain-openai)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured==0.7.12) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated~=1.2.0 (from argilla->unstructured==0.7.12)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.7.12) (1.14.1)\n",
            "Collecting numpy<2,>=1 (from langchain)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from argilla->unstructured==0.7.12)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting monotonic (from argilla->unstructured==0.7.12)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: rich!=13.1.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.7.12) (13.7.1)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.7.12) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured==0.7.12) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured==0.7.12) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured==0.7.12) (2024.1)\n",
            "Collecting olefile>=0.46 (from msg-parser->unstructured==0.7.12)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.7.12) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.7.12) (1.4.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured==0.7.12) (1.1.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured==0.7.12) (42.0.7)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->unstructured==0.7.12)\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured==0.7.12) (1.16.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-openai)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->unstructured==0.7.12) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich!=13.1.0->argilla->unstructured==0.7.12) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich!=13.1.0->argilla->unstructured==0.7.12) (2.16.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured==0.7.12) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich!=13.1.0->argilla->unstructured==0.7.12) (0.1.2)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171034 sha256=2cd4c6cb5e1133ed4dc1bf57c2bfaebcf37a24363a68f711fbc380c0c4fc2d20\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: monotonic, filetype, emoji, XlsxWriter, python-magic, python-docx, pypandoc, pinecone-client, pdf2image, packaging, orjson, olefile, numpy, mypy-extensions, jsonpointer, h11, ftfy, deprecated, backoff, typing-inspect, tiktoken, python-pptx, msg-parser, marshmallow, jsonpatch, httpcore, clean-text, pdfminer.six, langsmith, httpx, dataclasses-json, openai, langchain-core, argilla, unstructured, langchain-text-splitters, langchain-pinecone, langchain-openai, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed XlsxWriter-3.2.0 argilla-1.28.0 backoff-2.2.1 clean-text-0.6.0 dataclasses-json-0.6.6 deprecated-1.2.14 emoji-1.7.0 filetype-1.2.0 ftfy-6.2.0 h11-0.14.0 httpcore-1.0.5 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-openai-0.1.7 langchain-pinecone-0.1.1 langchain-text-splitters-0.0.2 langsmith-0.1.59 marshmallow-3.21.2 monotonic-1.6 msg-parser-1.2.0 mypy-extensions-1.0.0 numpy-1.23.5 olefile-0.47 openai-1.30.1 orjson-3.10.3 packaging-23.2 pdf2image-1.17.0 pdfminer.six-20231228 pinecone-client-3.2.2 pypandoc-1.13 python-docx-1.1.2 python-magic-0.4.27 python-pptx-0.6.23 tiktoken-0.7.0 typing-inspect-0.9.0 unstructured-0.7.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "36141c1294af403bba62b628e9b6b88e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dependencies"
      ],
      "metadata": {
        "id": "T4jIRdQ81k1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.vectorstores.pinecone import Pinecone\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from cleantext import clean\n",
        "import os\n",
        "import nltk\n",
        "import pinecone\n",
        "import openai"
      ],
      "metadata": {
        "id": "GNvcPz3L8i77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0004b74-d1ed-4298-a944-9782db0d4a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Input for URLs to build the RAG agent"
      ],
      "metadata": {
        "id": "rCxVY5w51oGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urls = []\n",
        "n_weblinks = int(input(\"How many web links you want the RAG agent to refer for response generation & insights? Enter here: \"))\n",
        "print(\"Enter your links below: \")\n",
        "for i in range(0, n_weblinks):\n",
        "  inp = input()\n",
        "  # appending the element in list\n",
        "  urls.append(inp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uedatwOEroC",
        "outputId": "74b6b2f3-721a-406a-8c99-25f7f0dbc0db"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many web links you want the RAG agent to refer for response generation & insights? Enter here: 1\n",
            "Enter your links below: \n",
            "https://adasci.org/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading URL through LangChain's UnstructuredURLLoader"
      ],
      "metadata": {
        "id": "r4B7aLvJ1w2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = UnstructuredURLLoader(urls=urls)\n",
        "urls = loader.load()"
      ],
      "metadata": {
        "id": "1v6pfwRg8i5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging urls into a single list\n",
        "documents = []\n",
        "documents.extend(urls)"
      ],
      "metadata": {
        "id": "WCxahzx28i3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "texts"
      ],
      "metadata": {
        "id": "uxsrLG_U8i1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f00f9b-768c-4a67-ca7e-c9aebd46b401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Skip to content\\n\\nUpskill your Team on Generative AI. Start here >\\n\\nMemberships\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tClose Memberships\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tOpen Memberships\\n\\nAccreditations\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tClose Accreditations\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tOpen Accreditations\\n\\nContinuous Learning\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tClose Continuous Learning\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tOpen Continuous Learning\\n\\nCorporate Trainings\\n\\nContact\\n\\nIndividual Membership', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Join the world’s leading Data Science professional community. You can access both General & Premium Memberships.\\n\\nLearn More\\n\\nCorporate Membership\\n\\nAny corporate, organization or academic institution having common interests in the AI field can become a member of ADaSci.\\n\\nLearn More\\n\\nChartered Data Scientist™\\n\\nThe Chartered Data Scientist (CDS) credential gives a strong understanding of advanced data science profession and in-depth, applied analytics skills.\\n\\nLearn More', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Learn More\\n\\nCertified Data Scientist - Associate Level\\n\\nBest suitable for the aspirants who want to start their career in the data science field, this certification.\\n\\nLearn More\\n\\nCertified Generative AI Engineer\\n\\nAn upskilling-linked certification initiative designed to recognize talent in generative AI and large language models.\\n\\nLearn More\\n\\nOur Latest Courses\\n\\nVector Search Techniques with Weaviate\\n\\n$39.99\\n\\nAdd to cart\\n\\nResponsible Generative AI With Purple Llama\\n\\n$39.99\\n\\nAdd to cart', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content=\"Add to cart\\n\\nAdvanced RAG with Pinecone\\n\\n$39.99\\n\\nAdd to cart\\n\\nAutonomous AI Agents and AI Copilots\\n\\n$59.99\\n\\nAdd to cart\\n\\nHi, Welcome back!\\n\\nForgot?\\n\\n\\n\\t\\t\\tDon't have an account?\\xa0\\n\\t\\t\\t\\n\\nRegister Now\\n\\nAccess all Courses\\n\\n$0.00\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t0\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tCart\\n\\nMembers Area\\n\\nA Global Professional Body of AI Professionals\\n\\nShaping the future of AI talent, Association of Data Scientists accredits and elevates professionals with recognized certifications and transformative corporate training.\", metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Join now to advance your AI expertise and achieve global recognition as a certified professional!\\n\\nBECOME A MEMBER\\n\\nSTART LEARNING AI\\n\\nOur Accreditations\\n\\nGet global recognition for AI skills\\n\\nChartered Data Scientist (CDS™)\\n\\nThe highest distinction in the data science profession. Not just earn a charter, but use it as a designation.\\n\\nLearn more\\n\\nCertified Data Scientist - Associate Level\\n\\nGlobal recognition of data science skills at the beginner level.\\n\\nLearn more', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Learn more\\n\\nCertified Generative AI Engineer\\n\\nAn upskilling-linked certification initiative designed to recognize talent in generative AI and large language models\\n\\nLearn more\\n\\nCorporate training programs on Generative AI\\n\\nGenerative AI Skill Development for Enterprises\\n\\nOur customized corporate training program on Generative AI provides a unique opportunity to empower, retain, and advance your talent.\\n\\nFind out more\\n\\nSecure Your Spot in the AI Revolution', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Accelerate your AI expertise with immersive courses and programs tailored for dynamic, hands-on learning.\\n\\nVector Search Techniques with Weaviate\\n\\n$39.99\\n\\nAdd to cart\\n\\nResponsible Generative AI With Purple Llama\\n\\n$39.99\\n\\nAdd to cart\\n\\nAdvanced RAG with Pinecone\\n\\n$39.99\\n\\nAdd to cart\\n\\nVisit the AI Academy\\n\\nJoin thousands of members and receive all benefits.\\n\\nBecome Our Member\\n\\nWe offer both Individual & Institutional Membership.\\n\\nFind out more\\n\\nLatest from our Blogs', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='The Generative AI Talent Gap: How Businesses Can Cultivate Their Own Experts\\n\\nHow to bridge the Generative AI talent gap through upskilling and reskilling initiatives?\\n\\nADaSci Announces the 4th Edition of Deep Learning DevCon (DLDC) 2024\\n\\nDive into the world of Generative AI and LLMs at DLDC 2024, the premier conference for cutting-edge AI research\\n\\nGenpact Launches SkyDive Global Campus Academy 2024 with ADaSci', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Bridging academia and industry, SkyDive transforms fresh graduates professionally.\\n\\nTransforming Market Surveys: A Journey from Concept to Implementation\\n\\nData Scientist pioneers market survey revolution through generative AI, transforming data synthesis for efficiency.\\n\\nThe Role of Retrieval-Augmented Generative Models in Ad Campaign\\n\\nExplore programmatic advertising’s transformation using large language models for efficient and innovative campaign strategies.', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Unlocking Insights: AI’s Role in Oil Data Search\\n\\nAI transforms oil exploration, streamlines workflows, and enhances document analysis for more efficient energy solutions.\\n\\nFrom Complexity to Clarity: AI’s Role in Narcotics Investigations\\n\\nRevolutionizing narcotics enforcement with an innovative AI companion, transforming investigations with guidance and support.\\n\\nUnlocking the Power of AI Pair Programming with Gemini', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Gemini AI revolutionizes data engineering, coding, and support processes, enhancing UI design, recommendations, and enterprise applications.\\n\\nThe Power of Multimodal Language Models Unveiled\\n\\nDiscover transformative AI insights with multimodal language models, revolutionizing industries and unlocking innovative solutions.\\n\\nRead all our Blogs\\n\\nOur Upcoming Conference\\n\\nDeep Learning DevCon 2024', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Join us to hear some of the leading professionals & researchers that are pushing the boundaries of this very interesting area.\\n\\nRegister\\n\\nNot a member, but still want to know what we are upto? Subscribe to our Newsletter\\n\\nStart Free Trial\\n\\nThe power of intelligence to propel science and make a difference\\n\\nOur Accrediations\\n\\nChartered Data Scientist™ (CDS)\\n\\nCertified Data Scientist - Associate Level\\n\\nCertified Generative AI Engineer\\n\\nCDS Program\\n\\nAbout CDS\\n\\nExam Information', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Exam Information\\n\\nCandidate Body of Knowledge (CBOK)\\n\\nExam Structure\\n\\nExam Cost and Registration Fees\\n\\nEthical & Standards for Chartered Data Scientists (CDS)\\n\\nHow to Earn the CDS Charter\\n\\nTerms & Conditions For CDS™\\n\\nMembership\\n\\nIndividual Membership\\n\\nInstitutional Membership\\n\\nAbout\\n\\nAbout ADaSci\\n\\nContinuous Learning\\n\\nTeam\\n\\nPrivacy Policy\\n\\nTerms and Conditions\\n\\nChapters\\n\\nBlogs\\n\\nContact\\n\\nFor Organizations\\n\\nCorporate Trainings\\n\\nCDS for Organizations\\n\\nCorporate Membership\\n\\nJournal\\n\\nLattice', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Journal\\n\\nLattice\\n\\nAbout\\n\\nReview Committee\\n\\nTwitter\\n\\nFacebook-f\\n\\nLinkedin\\n\\n© 2024 All rights reserved Association of Data Scientists', metadata={'source': 'https://adasci.org/'})]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning URL Content"
      ],
      "metadata": {
        "id": "5ZvdzTJ0rMCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_url_text = clean(text=texts,\n",
        "            fix_unicode=True,\n",
        "            to_ascii=True,\n",
        "            lower=True,\n",
        "            no_line_breaks=False,\n",
        "            no_urls=False,\n",
        "            no_emails=False,\n",
        "            no_phone_numbers=False,\n",
        "            no_numbers=False,\n",
        "            no_digits=False,\n",
        "            no_currency_symbols=False,\n",
        "            no_punct=False,\n",
        "            replace_with_punct=\"\",\n",
        "            replace_with_url=\"This is a URL\",\n",
        "            replace_with_email=\"Email\",\n",
        "            replace_with_phone_number=\"\",\n",
        "            replace_with_number=\"123\",\n",
        "            replace_with_digit=\"0\",\n",
        "            replace_with_currency_symbol=\"$\",\n",
        "            lang=\"en\"\n",
        "            )\n",
        "clean_url_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "f_BMDRR5mVUs",
        "outputId": "d0c511ea-8ae3-4f35-cbe5-cf413c6dc911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[document(page_content=\\'skip to content\\nupskill your team on generative ai. start here >\\nmemberships\\nclose memberships\\nopen memberships\\naccreditations\\nclose accreditations\\nopen accreditations\\ncontinuous learning\\nclose continuous learning\\nopen continuous learning\\ncorporate trainings\\ncontact\\nindividual membership\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'join the world\\'s leading data science professional community. you can access both general & premium memberships.\\nlearn more\\ncorporate membership\\nany corporate, organization or academic institution having common interests in the ai field can become a member of adasci.\\nlearn more\\nchartered data scientist™️\\nthe chartered data scientist (cds) credential gives a strong understanding of advanced data science profession and in-depth, applied analytics skills.\\nlearn more\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'learn more\\ncertified data scientist - associate level\\nbest suitable for the aspirants who want to start their career in the data science field, this certification.\\nlearn more\\ncertified generative ai engineer\\nan upskilling-linked certification initiative designed to recognize talent in generative ai and large language models.\\nlearn more\\nour latest courses\\nvector search techniques with weaviate\\n$39.99\\nadd to cart\\nresponsible generative ai with purple llama\\n$39.99\\nadd to cart\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\"add to cart\\nadvanced rag with pinecone\\n$39.99\\nadd to cart\\nautonomous ai agents and ai copilots\\n$59.99\\nadd to cart\\nhi, welcome back!\\nforgot?\\ndon\\'t have an account?\\nregister now\\naccess all courses\\n$0.00\\n0\\ncart\\nmembers area\\na global professional body of ai professionals\\nshaping the future of ai talent, association of data scientists accredits and elevates professionals with recognized certifications and transformative corporate training.\", metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'join now to advance your ai expertise and achieve global recognition as a certified professional!\\nbecome a member\\nstart learning ai\\nour accreditations\\nget global recognition for ai skills\\nchartered data scientist (cds™️)\\nthe highest distinction in the data science profession. not just earn a charter, but use it as a designation.\\nlearn more\\ncertified data scientist - associate level\\nglobal recognition of data science skills at the beginner level.\\nlearn more\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'learn more\\ncertified generative ai engineer\\nan upskilling-linked certification initiative designed to recognize talent in generative ai and large language models\\nlearn more\\ncorporate training programs on generative ai\\ngenerative ai skill development for enterprises\\nour customized corporate training program on generative ai provides a unique opportunity to empower, retain, and advance your talent.\\nfind out more\\nsecure your spot in the ai revolution\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'accelerate your ai expertise with immersive courses and programs tailored for dynamic, hands-on learning.\\nvector search techniques with weaviate\\n$39.99\\nadd to cart\\nresponsible generative ai with purple llama\\n$39.99\\nadd to cart\\nadvanced rag with pinecone\\n$39.99\\nadd to cart\\nvisit the ai academy\\njoin thousands of members and receive all benefits.\\nbecome our member\\nwe offer both individual & institutional membership.\\nfind out more\\nlatest from our blogs\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'the generative ai talent gap: how businesses can cultivate their own experts\\nhow to bridge the generative ai talent gap through upskilling and reskilling initiatives?\\nadasci announces the 4th edition of deep learning devcon (dldc) 2024\\ndive into the world of generative ai and llms at dldc 2024, the premier conference for cutting-edge ai research\\ngenpact launches skydive global campus academy 2024 with adasci\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'bridging academia and industry, skydive transforms fresh graduates professionally.\\ntransforming market surveys: a journey from concept to implementation\\ndata scientist pioneers market survey revolution through generative ai, transforming data synthesis for efficiency.\\nthe role of retrieval-augmented generative models in ad campaign\\nexplore programmatic advertising\\'s transformation using large language models for efficient and innovative campaign strategies.\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'unlocking insights: ai\\'s role in oil data search\\nai transforms oil exploration, streamlines workflows, and enhances document analysis for more efficient energy solutions.\\nfrom complexity to clarity: ai\\'s role in narcotics investigations\\nrevolutionizing narcotics enforcement with an innovative ai companion, transforming investigations with guidance and support.\\nunlocking the power of ai pair programming with gemini\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'gemini ai revolutionizes data engineering, coding, and support processes, enhancing ui design, recommendations, and enterprise applications.\\nthe power of multimodal language models unveiled\\ndiscover transformative ai insights with multimodal language models, revolutionizing industries and unlocking innovative solutions.\\nread all our blogs\\nour upcoming conference\\ndeep learning devcon 2024\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'join us to hear some of the leading professionals & researchers that are pushing the boundaries of this very interesting area.\\nregister\\nnot a member, but still want to know what we are upto? subscribe to our newsletter\\nstart free trial\\nthe power of intelligence to propel science and make a difference\\nour accrediations\\nchartered data scientist™️ (cds)\\ncertified data scientist - associate level\\ncertified generative ai engineer\\ncds program\\nabout cds\\nexam information\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'exam information\\ncandidate body of knowledge (cbok)\\nexam structure\\nexam cost and registration fees\\nethical & standards for chartered data scientists (cds)\\nhow to earn the cds charter\\nterms & conditions for cds™️\\nmembership\\nindividual membership\\ninstitutional membership\\nabout\\nabout adasci\\ncontinuous learning\\nteam\\nprivacy policy\\nterms and conditions\\nchapters\\nblogs\\ncontact\\nfor organizations\\ncorporate trainings\\ncds for organizations\\ncorporate membership\\njournal\\nlattice\\', metadata={\\'source\\': \\'https://adasci.org/\\'}), document(page_content=\\'journal\\nlattice\\nabout\\nreview committee\\ntwitter\\nfacebook-f\\nlinkedin\\n©️ 2024 all rights reserved association of data scientists\\', metadata={\\'source\\': \\'https://adasci.org/\\'})]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI API Key Setting\n",
        "\n"
      ],
      "metadata": {
        "id": "dAt6MEyE17b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the OpenAI API key as an environment variable\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_APIKEY\")"
      ],
      "metadata": {
        "id": "ZQTZHqju8iy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pinecone API Setting"
      ],
      "metadata": {
        "id": "NK8hff9Q2Ask"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the pinecone key\n",
        "from pinecone import Pinecone\n",
        "os.environ[\"PINECONE_API_KEY\"] = userdata.get(\"PINECONE_API\")\n",
        "\n",
        "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "\n",
        "# configure client\n",
        "pc = Pinecone(api_key=api_key)"
      ],
      "metadata": {
        "id": "KbJqgcuP8iwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
        "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
        "\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)"
      ],
      "metadata": {
        "id": "5BQGlaqmiiXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "index_name = \"myindex\"\n",
        "\n",
        "if index_name in pc.list_indexes().names():\n",
        "    pc.delete_index(index_name)\n",
        "\n",
        "# we create a new index\n",
        "pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,  # dimensionality of text-embedding-ada-002\n",
        "        metric='dotproduct',\n",
        "        spec=spec\n",
        "    )\n",
        "\n",
        "# wait for index to be initialized\n",
        "while not pc.describe_index(index_name).status['ready']:\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "id": "Yn0rNxWTipXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = pc.Index(index_name)\n",
        "index.describe_index_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xymHAfg-i8On",
        "outputId": "cbcb25cc-22be-4bc3-eb92-7183b4513f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n"
      ],
      "metadata": {
        "id": "bT_FIbRejPK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
        "        texts,\n",
        "        index_name=index_name,\n",
        "        embedding=embeddings\n",
        "    )"
      ],
      "metadata": {
        "id": "OWEtcOTWmNz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is AdaSci?\"\n",
        "vectorstore.similarity_search(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5rmJYSxkW70",
        "outputId": "afbe7f76-3700-40f1-ad77-e6bdb44f1f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Join the world’s leading Data Science professional community. You can access both General & Premium Memberships.\\n\\nLearn More\\n\\nCorporate Membership\\n\\nAny corporate, organization or academic institution having common interests in the AI field can become a member of ADaSci.\\n\\nLearn More\\n\\nChartered Data Scientist™\\n\\nThe Chartered Data Scientist (CDS) credential gives a strong understanding of advanced data science profession and in-depth, applied analytics skills.\\n\\nLearn More', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='The Generative AI Talent Gap: How Businesses Can Cultivate Their Own Experts\\n\\nHow to bridge the Generative AI talent gap through upskilling and reskilling initiatives?\\n\\nADaSci Announces the 4th Edition of Deep Learning DevCon (DLDC) 2024\\n\\nDive into the world of Generative AI and LLMs at DLDC 2024, the premier conference for cutting-edge AI research\\n\\nGenpact Launches SkyDive Global Campus Academy 2024 with ADaSci', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Join now to advance your AI expertise and achieve global recognition as a certified professional!\\n\\nBECOME A MEMBER\\n\\nSTART LEARNING AI\\n\\nOur Accreditations\\n\\nGet global recognition for AI skills\\n\\nChartered Data Scientist (CDS™)\\n\\nThe highest distinction in the data science profession. Not just earn a charter, but use it as a designation.\\n\\nLearn more\\n\\nCertified Data Scientist - Associate Level\\n\\nGlobal recognition of data science skills at the beginner level.\\n\\nLearn more', metadata={'source': 'https://adasci.org/'}),\n",
              " Document(page_content='Journal\\n\\nLattice\\n\\nAbout\\n\\nReview Committee\\n\\nTwitter\\n\\nFacebook-f\\n\\nLinkedin\\n\\n© 2024 All rights reserved Association of Data Scientists', metadata={'source': 'https://adasci.org/'})]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building and Execution"
      ],
      "metadata": {
        "id": "CTQOynAWmALD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "# completion llm\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=userdata.get(\"OPENAI_APIKEY\"),\n",
        "    model_name='gpt-3.5-turbo',\n",
        "    temperature=0.0\n",
        ")\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever()\n",
        ")\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xgs-MVqcrE12",
        "outputId": "ed60bb79-5690-422b-c4af-b81fa5923656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The primary goal of ADaSci is to advance AI expertise and provide global recognition as a certified professional in the field of data science and artificial intelligence. They offer memberships, accreditations, and opportunities for upskilling and reskilling in AI-related areas.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_prompt = \"You are a researcher who is going to search the web links, summarize them and share insights as asked\""
      ],
      "metadata": {
        "id": "6SxPr2Xpyqf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the primary goal of AdaSci?\"\n",
        "result = qa({\"query\": query, \"prompt\": initial_prompt})"
      ],
      "metadata": {
        "id": "Ml9_APDWzOBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2451669b-ec3e-45d1-9db0-cf0f157963be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYQAW7dQzP6A",
        "outputId": "e5c7a250-cb11-414c-9bc7-bf7041dd5f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The primary goal of ADaSci is to advance AI expertise and provide global recognition as a certified professional in the field of data science and artificial intelligence. They offer memberships, accreditations, and opportunities for upskilling and reskilling in AI-related areas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cfKvUF6trAG3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}